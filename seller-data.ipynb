{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Configuration\n",
    "SERVICE_ACCOUNT_FILE = '/Users/deepshah/Downloads/tiffinstash-key.json'\n",
    "FOLDER_ID = '1t5s3Zf5nGOceskozz74tta9H5vd9mawp'\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.metadata.readonly']\n",
    "\n",
    "def get_sheet_ids():\n",
    "    creds = service_account.Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "    \n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    query = (f\"'{FOLDER_ID}' in parents and \"\n",
    "             f\"mimeType = 'application/vnd.google-apps.spreadsheet' and \"\n",
    "             f\"trashed = false\")\n",
    "\n",
    "    # We only request the 'id' field to keep the response lean\n",
    "    results = service.files().list(\n",
    "        q=query,\n",
    "        fields=\"files(id)\"\n",
    "    ).execute()\n",
    "\n",
    "    # Extract IDs into a simple Python list\n",
    "    file_ids = [file['id'] for file in results.get('files', [])]\n",
    "    \n",
    "    return file_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0614b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "import pandas as pd\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "# 1. Define the scope\n",
    "SCOPES = [\n",
    "    \"https://www.googleapis.com/auth/drive\"\n",
    "]\n",
    "\n",
    "# 2. Authenticate using your Service Account key file\n",
    "# Replace with the actual path to your JSON key file\n",
    "SERVICE_ACCOUNT_FILE = '/Users/deepshah/Downloads/tiffinstash-key.json' \n",
    "\n",
    "creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# 3. Open the Google Sheet\n",
    "# You can open by title, url, or key. Opening by key is most robust.\n",
    "# Example URL: https://docs.google.com/spreadsheets/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/edit\n",
    "SHEET_ID = '1UMfiU20U3DXL5st0PTRTiq5xQ_cB10_nrDvexmrapsQ' \n",
    "\n",
    "try:\n",
    "    # Open the spreadsheet\n",
    "    sh = client.open_by_key(SHEET_ID)\n",
    "    \n",
    "    # Select the specific worksheet (tab) by index (0 is the first one) or name\n",
    "    worksheet = sh.get_worksheet(3) \n",
    "    # OR: worksheet = sh.worksheet(\"Sheet1\")\n",
    "\n",
    "    # 4. Get all values and convert to DataFrame\n",
    "    data = worksheet.get_all_records() # Returns a list of dictionaries\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    print(\"Data extracted successfully:\")\n",
    "    print(df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error reading Google Sheet: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db093975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import requests\n",
    "import certifi\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional, Dict, Any\n",
    "from google.oauth2 import service_account\n",
    "from google.auth import default\n",
    "import json\n",
    "\n",
    "def get_credentials(scopes=None):\n",
    "    \"\"\"\n",
    "    Gets Google Service Account credentials from environment variable, \n",
    "    mounted secret file, or local development file.\n",
    "    \"\"\"\n",
    "    # 1. Check if key content is in environment variable\n",
    "    key_content = os.environ.get(\"tiffinstash-sa-key\")\n",
    "    if key_content:\n",
    "        try:\n",
    "            info = json.loads(key_content)\n",
    "            creds = service_account.Credentials.from_service_account_info(info)\n",
    "            if scopes:\n",
    "                creds = creds.with_scopes(scopes)\n",
    "            return creds\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to parse 'tiffinstash-sa-key' env var as JSON: {e}\")\n",
    "\n",
    "    # 2. Check for mounted secret file or local development file\n",
    "    possible_paths = [\n",
    "        \"/etc/tiffinstash-sa-key\",\n",
    "        \"/Users/deepshah/Downloads/tiffinstash-key.json\"\n",
    "    ]\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            return service_account.Credentials.from_service_account_file(path, scopes=scopes)\n",
    "    \n",
    "    # 3. Fallback to application default credentials (ADC)\n",
    "    logger.info(\"No service account key found, falling back to Application Default Credentials\")\n",
    "    credentials, _ = default()\n",
    "    if scopes:\n",
    "        credentials = credentials.with_scopes(scopes)\n",
    "    return credentials\n",
    "\n",
    "\"\"\"\n",
    "Logic for processing seller data from Google Sheets.\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "\n",
    "def update_column_k(val: str) -> str:\n",
    "    \"\"\"Map seller codes to full names.\"\"\"\n",
    "    if not val:\n",
    "        return val\n",
    "    v = str(val).lower()\n",
    "    mapping = {\n",
    "        'kt': 'KHAOT', 'lk': 'LALKT', 'sw': 'TSWAD', 'tp': 'TPROS', 'mj': 'MIJOY',\n",
    "        'vs': 'VISWA', 'if': 'INFLV', 'kk': 'KHAOK', 'bv': 'BHAVS', 'an': 'ANGTH',\n",
    "        'sp': 'SPICE', 'ca': 'CHEFA', 'fg': 'FIERY', 'fm': 'FMONK', 'ks': 'KRISK',\n",
    "        'kl': 'KERAL', 'sb': 'SPBAR', 'rd': 'RADHA', 'dn': 'DELHI', 'sc': 'SATVK',\n",
    "        'rn': 'RNBIT', 'sm': 'SUBMA', 'hk': 'HEMIK', 'pr': 'PINDI', 'ms': 'MOKSH',\n",
    "        'mc': 'MASCO', 'cb': 'CBAKE', 'hf': 'HOMEF', 'rv': 'RITAJ', 'mu': 'MUMKT',\n",
    "        'dr': 'DSRAS', 'mz': 'MITZI', 'mn': 'AMINA'\n",
    "    }\n",
    "    for k, mapped in mapping.items():\n",
    "        if k in v:\n",
    "            return mapped\n",
    "    return val\n",
    "\n",
    "def update_seller_delivery(val: str) -> str:\n",
    "    \"\"\"Normalize seller delivery status.\"\"\"\n",
    "    if not val or (isinstance(val, str) and not val.strip()):\n",
    "        return \"No\"\n",
    "    if isinstance(val, str):\n",
    "        v = val.strip().lower()\n",
    "        if v in (\"no\", \"yes\"):\n",
    "            return v.capitalize()\n",
    "        if v == \"yes ($1.99/day)\":\n",
    "            return \"Yes\"\n",
    "    return val\n",
    "\n",
    "def apply_td_to_vd(v_val: str, l_val: str) -> str:\n",
    "    \"\"\"Switch TD to VD for Midday deliveries.\"\"\"\n",
    "    if v_val == \"MIDDAY\" and l_val == \"TD\":\n",
    "        return \"VD\"\n",
    "    return l_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271bc6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shopify Order Field Names\n",
    "SHOPIFY_ORDER_FIELDNAMES = [\n",
    "    \"ORDER ID\",\n",
    "    \"DATE\",\n",
    "    \"NAME\",\n",
    "    \"Shipping address phone numeric\",\n",
    "    \"phone_edit\",\n",
    "    \"EMAIL\",\n",
    "    \"HOUSE UNIT NO\",\n",
    "    \"ADDRESS LINE 1\",\n",
    "    \"Select Delivery City\",\n",
    "    \"Shipping address city\",\n",
    "    \"ZIP\",\n",
    "    \"SKU\",\n",
    "    \"Delivery Instructions (for drivers)\",\n",
    "    \"Order Instructions (for sellers)\",\n",
    "    \"Delivery Time\",\n",
    "    \"Dinner Delivery\",\n",
    "    \"Lunch Delivery\",\n",
    "    \"Lunch Delivery Time\",\n",
    "    \"Lunch Time\",\n",
    "    \"Delivery between\",\n",
    "    \"deliverytime_edit\",\n",
    "    \"QUANTITY\",\n",
    "    \"Select Start Date\",\n",
    "    \"Delivery city\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df4fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHEET_URLS = get_sheet_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8084d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gspread\n",
    "import time\n",
    "from datetime import datetime\n",
    "from fastapi import APIRouter, HTTPException\n",
    "from google.oauth2 import service_account\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "SERVICE_ACCOUNT_FILE = '/Users/deepshah/Downloads/tiffinstash-key.json'\n",
    "FOLDER_ID = '1t5s3Zf5nGOceskozz74tta9H5vd9mawp'\n",
    "SCOPES = [\n",
    "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "    \"https://www.googleapis.com/auth/drive.metadata.readonly\"\n",
    "]\n",
    "\n",
    "def get_credentials():\n",
    "    return service_account.Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "\n",
    "# --- OPTIMIZED WORKER ---\n",
    "\n",
    "@retry(\n",
    "    retry=retry_if_exception_type(gspread.exceptions.APIError),\n",
    "    wait=wait_exponential(multiplier=2, min=10, max=60), # Increased wait time\n",
    "    stop=stop_after_attempt(3),\n",
    "    before_sleep=lambda retry_state: print(f\"Quota hit. Retrying in {retry_state.next_action.sleep}s...\")\n",
    ")\n",
    "def fetch_single_sheet_data(client, sheet_id):\n",
    "    \"\"\"Worker function: Now used sequentially to prevent burst errors.\"\"\"\n",
    "    # Note: open_by_key = 1 Read Request, get_all_values = 1 Read Request. \n",
    "    # Total = 2 requests per sheet.\n",
    "    sh = client.open_by_key(sheet_id)\n",
    "    try:\n",
    "        worksheet = sh.worksheet(\"SD DATA\")\n",
    "    except gspread.WorksheetNotFound:\n",
    "        return []\n",
    "\n",
    "    values = worksheet.get_all_values()\n",
    "    if len(values) < 2:\n",
    "        return []\n",
    "\n",
    "    headers = values[0][2:26]\n",
    "    rows = []\n",
    "    for row in values[1:]:\n",
    "        if len(row) > 23 and \"ongoing\" in str(row[23]).lower():\n",
    "            target_values = row[2:26]\n",
    "            if len(target_values) == len(headers):\n",
    "                rows.append(dict(zip(headers, target_values)))\n",
    "    return rows\n",
    "\n",
    "# --- MAIN ROUTE ---\n",
    "\n",
    "def fetch_aggregated_seller_data():\n",
    "    try:\n",
    "        creds = get_credentials()\n",
    "        client = gspread.authorize(creds)\n",
    "        \n",
    "        # 1. Fetch IDs (This is 1 Drive API request)\n",
    "        from googleapiclient.discovery import build\n",
    "        drive_service = build('drive', 'v3', credentials=creds)\n",
    "        query = f\"'{FOLDER_ID}' in parents and mimeType = 'application/vnd.google-apps.spreadsheet' and trashed = false\"\n",
    "        results = drive_service.files().list(q=query, fields=\"files(id)\").execute()\n",
    "        sheet_ids = [f['id'] for f in results.get('files', [])]\n",
    "        \n",
    "        if not sheet_ids:\n",
    "            return []\n",
    "\n",
    "        all_data = []\n",
    "        total = len(sheet_ids)\n",
    "        \n",
    "        print(f\"Starting controlled fetch for {total} sheets...\")\n",
    "\n",
    "        # 2. Sequential Processing with Mandatory Delay\n",
    "        for idx, sid in enumerate(sheet_ids):\n",
    "            print(f\"[{idx+1}/{total}] Fetching sheet: {sid}\")\n",
    "            \n",
    "            data = fetch_single_sheet_data(client, sid)\n",
    "            if data:\n",
    "                all_data.extend(data)\n",
    "            \n",
    "            # --- THE QUOTA PROTECTOR ---\n",
    "            # Each sheet takes 2 requests. \n",
    "            # To stay under 60 requests/min, we need to ensure we don't \n",
    "            # do more than 30 sheets per minute. \n",
    "            # 60 seconds / 30 sheets = 2 seconds per sheet.\n",
    "            if idx < total - 1: # Don't sleep after the very last sheet\n",
    "                time.sleep(2.0) \n",
    "\n",
    "        # 3. Transform\n",
    "        final_data = transform_to_master_format(all_data)\n",
    "        \n",
    "        df_final = pd.DataFrame(final_data)\n",
    "        return df_final.replace([np.inf, -np.inf], np.nan).where(pd.notnull(df_final), None).to_dict(orient=\"records\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Aggregation failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20d955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=fetch_aggregated_seller_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba270d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82887430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
